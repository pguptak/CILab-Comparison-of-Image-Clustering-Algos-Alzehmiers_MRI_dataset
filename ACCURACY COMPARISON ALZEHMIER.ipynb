{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "846d490b-3e17-4fdf-ba30-306f91676408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0, Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2985bdd2-1d00-4394-8002-ac40e7582231",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbf7d32d-f808-461d-8e98-cc7d2fed05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"ALZ_working\\labels.csv\")\n",
    "eff_kmeans_df = pd.read_csv(\"EfficientNetB0_KMeans.csv\")\n",
    "\n",
    "# If you have Xception-Birch file:\n",
    "xcep_birch_df = pd.read_csv(\"Xception_Birch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aafdad5-86b6-4c49-b9ab-c897de0187d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, label_column):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[\"label_encoded\"] = le.fit_transform(df[label_column])\n",
    "\n",
    "    num_classes = df[\"label_encoded\"].nunique()\n",
    "\n",
    "    X = df[\"image_name\"].values\n",
    "    y = to_categorical(df[\"label_encoded\"], num_classes)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=SEED,\n",
    "        stratify=df[\"label_encoded\"]\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=0.5,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e6897af-bec7-4d5c-8fd0-4a5ce53c4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MIXED_FOLDER = \"ALZ_working\\mixed_images\"   \n",
    "\n",
    "def load_image(image_name):\n",
    "    full_path = os.path.join(MIXED_FOLDER, image_name)\n",
    "\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        full_path,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE)\n",
    "    )\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_dataset(X, y):\n",
    "    images = np.array([load_image(name) for name in X])\n",
    "    return images, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b066966e-ba5b-4a9a-8a74-6540f985c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnet(num_classes):\n",
    "\n",
    "    base = EfficientNetB0(\n",
    "        weights=None,            # NO pretrained\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4309ea38-30c5-4a30-8920-3c799f83d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xception(num_classes):\n",
    "\n",
    "    base = Xception(\n",
    "        weights=None,           # NO pretrained\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b71004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_name', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(original_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b188eb20-2d16-46a1-bdd0-301dfdd8ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 1s/step - accuracy: 0.5098 - loss: 1.0466 - val_accuracy: 0.3646 - val_loss: 1.1060\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.5864 - loss: 0.8550 - val_accuracy: 0.4823 - val_loss: 3.2254\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.6922 - loss: 0.6975 - val_accuracy: 0.4823 - val_loss: 3.2425\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.7980 - loss: 0.5058 - val_accuracy: 0.4823 - val_loss: 28.5395\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.8632 - loss: 0.3483 - val_accuracy: 0.5094 - val_loss: 2.9594\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9098 - loss: 0.2316 - val_accuracy: 0.4969 - val_loss: 4.4960\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.9279 - loss: 0.1956 - val_accuracy: 0.7521 - val_loss: 1.1528\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9449 - loss: 0.1565 - val_accuracy: 0.7198 - val_loss: 1.1158\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9531 - loss: 0.1289 - val_accuracy: 0.8781 - val_loss: 0.3425\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.9614 - loss: 0.1023 - val_accuracy: 0.9073 - val_loss: 0.2716\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.9115 - loss: 0.2637\n",
      "EfficientNet trained on ORIGINAL labels Accuracy: 0.9114583134651184\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(original_df,\"label\")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "model_eff_original = build_efficientnet(num_classes)\n",
    "\n",
    "model_eff_original.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "loss1, acc1 = model_eff_original.evaluate(X_test_img, y_test)\n",
    "print(\"EfficientNet trained on ORIGINAL labels Accuracy:\", acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c886d688-7966-4f2a-9dc5-c1d325f211e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 1s/step - accuracy: 0.8306 - loss: 0.4716 - val_accuracy: 0.8229 - val_loss: 1.0512\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.8935 - loss: 0.2417 - val_accuracy: 0.8229 - val_loss: 1.3572\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - accuracy: 0.9141 - loss: 0.1916 - val_accuracy: 0.8229 - val_loss: 1.3543\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9400 - loss: 0.1417 - val_accuracy: 0.8229 - val_loss: 2.9152\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.9413 - loss: 0.1438 - val_accuracy: 0.8510 - val_loss: 0.5014\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 1s/step - accuracy: 0.9444 - loss: 0.1264 - val_accuracy: 0.9021 - val_loss: 0.2756\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.9580 - loss: 0.1003 - val_accuracy: 0.9302 - val_loss: 0.1858\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.9681 - loss: 0.0793 - val_accuracy: 0.8896 - val_loss: 0.4356\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.9681 - loss: 0.0817 - val_accuracy: 0.9333 - val_loss: 0.1960\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.9730 - loss: 0.0691 - val_accuracy: 0.9167 - val_loss: 0.2867\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.9031 - loss: 0.3170\n",
      "\n",
      "EfficientNet trained on KMeans labels Accuracy: 0.903124988079071\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    eff_kmeans_df,\n",
    "    label_column=\"cluster_label\"   # <-- adjust if needed\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_eff_cluster = build_efficientnet(num_classes)\n",
    "\n",
    "model_eff_cluster.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "loss2, acc2 = model_eff_cluster.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nEfficientNet trained on KMeans labels Accuracy:\", acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3161b3ac-2ac2-4153-9c18-c2c9fd0bfb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 2s/step - accuracy: 0.5790 - loss: 0.9300 - val_accuracy: 0.4823 - val_loss: 1.2893\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.7138 - loss: 0.6832 - val_accuracy: 0.4823 - val_loss: 1.1226\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 2s/step - accuracy: 0.8147 - loss: 0.4635 - val_accuracy: 0.4823 - val_loss: 1.9240\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.8888 - loss: 0.2921 - val_accuracy: 0.6760 - val_loss: 1.0719\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.9406 - loss: 0.1536 - val_accuracy: 0.6562 - val_loss: 1.4193\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.9478 - loss: 0.1350 - val_accuracy: 0.2240 - val_loss: 7.9630\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.9632 - loss: 0.1076 - val_accuracy: 0.8531 - val_loss: 0.6617\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.9708 - loss: 0.0840 - val_accuracy: 0.8167 - val_loss: 0.7504\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - accuracy: 0.9741 - loss: 0.0686 - val_accuracy: 0.8531 - val_loss: 0.5294\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 2s/step - accuracy: 0.9830 - loss: 0.0452 - val_accuracy: 0.1927 - val_loss: 9.2735\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 493ms/step - accuracy: 0.1969 - loss: 9.7253\n",
      "\n",
      "Xception trained on ORIGINAL labels Accuracy: 0.19687500596046448\n"
     ]
    }
   ],
   "source": [
    "# Prepare data (original labels)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    original_df,\n",
    "    label_column=\"label\"   # original label column\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# Build model\n",
    "model_x_original = build_xception(num_classes)\n",
    "\n",
    "# Train\n",
    "model_x_original.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss3, acc3 = model_x_original.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nXception trained on ORIGINAL labels Accuracy:\", acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a175b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 2s/step - accuracy: 0.7748 - loss: 0.5313 - val_accuracy: 0.0979 - val_loss: 1.2290\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 2s/step - accuracy: 0.8520 - loss: 0.3482 - val_accuracy: 0.0979 - val_loss: 1.9323\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 2s/step - accuracy: 0.8725 - loss: 0.2972 - val_accuracy: 0.0979 - val_loss: 4.4404\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.8886 - loss: 0.2734 - val_accuracy: 0.6906 - val_loss: 0.7595\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.9076 - loss: 0.2273 - val_accuracy: 0.9042 - val_loss: 0.2128\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.9076 - loss: 0.2204 - val_accuracy: 0.8896 - val_loss: 0.2704\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.9301 - loss: 0.1753 - val_accuracy: 0.6562 - val_loss: 1.6542\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 2s/step - accuracy: 0.9335 - loss: 0.1709 - val_accuracy: 0.5260 - val_loss: 2.1676\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 2s/step - accuracy: 0.9339 - loss: 0.1686 - val_accuracy: 0.4469 - val_loss: 2.6493\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 2s/step - accuracy: 0.9402 - loss: 0.1486 - val_accuracy: 0.4083 - val_loss: 3.6235\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.4042 - loss: 3.5851\n",
      "\n",
      "Xception trained on Birch labels Accuracy: 0.40416666865348816\n"
     ]
    }
   ],
   "source": [
    "# Prepare data (Birch cluster labels)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    xcep_birch_df,\n",
    "    label_column=\"cluster_label\"   # <-- change if different\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# Build model\n",
    "model_x_cluster = build_xception(num_classes)\n",
    "\n",
    "# Train\n",
    "model_x_cluster.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss4, acc4 = model_x_cluster.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nXception trained on Birch labels Accuracy:\", acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "938c1dd8-44ad-4d7d-8784-3aaf1f6beafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FINAL RESULTS ==========\n",
      "EfficientNet Original Accuracy: 0.9114583134651184\n",
      "EfficientNet Cluster Accuracy : 0.903124988079071\n",
      "Xception Original Accuracy    : 0.19687500596046448\n",
      "Xception Cluster Accuracy     : 0.40416666865348816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# FINAL COMPARISON\n",
    "# =========================\n",
    "\n",
    "print(\"\\n========== FINAL RESULTS ==========\")\n",
    "print(\"EfficientNet Original Accuracy:\", acc1)\n",
    "print(\"EfficientNet Cluster Accuracy :\", acc2)\n",
    "print(\"Xception Original Accuracy    :\", acc3)\n",
    "print(\"Xception Cluster Accuracy     :\", acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc432ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
