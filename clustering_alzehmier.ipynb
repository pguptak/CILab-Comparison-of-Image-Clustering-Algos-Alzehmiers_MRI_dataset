{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc3736-9a42-4365-9b31-fdf296a81c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn-extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13564c30-d326-43de-8e34-b92a776aaaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.41-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=1.6->hdbscan) (3.6.0)\n",
      "Downloading hdbscan-0.8.41-cp313-cp313-win_amd64.whl (671 kB)\n",
      "   ---------------------------------------- 0.0/671.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 671.7/671.7 kB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: hdbscan\n",
      "Successfully installed hdbscan-0.8.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df533264-1699-43b1-b857-21196df1b58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-fuzzy\n",
      "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
      "   ---------------------------------------- 0.0/920.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/920.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 920.8/920.8 kB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-fuzzy\n",
      "Successfully installed scikit-fuzzy-0.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-fuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947f6bb4-cfec-4b85-ac74-b0895f5e5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import (\n",
    "    KMeans,\n",
    "    MiniBatchKMeans,\n",
    "    AgglomerativeClustering,\n",
    "    SpectralClustering,\n",
    "    MeanShift,\n",
    "    AffinityPropagation,\n",
    "    DBSCAN,\n",
    "    OPTICS,\n",
    "    Birch,\n",
    "    BisectingKMeans\n",
    ")\n",
    "\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import hdbscan\n",
    "import skfuzzy as fuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58997ba-eb4b-4f12-af6a-8de8f5ebf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "original_df = pd.read_csv(\"ALZ_working/labels.csv\")\n",
    "\n",
    "image_names = original_df[\"image_name\"].values\n",
    "original_labels = original_df[\"label\"].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "original_labels_enc = le.fit_transform(original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b360451-97dd-4468-80b2-8b3ad327d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_change(original, clustered):\n",
    "    return (np.sum(original != clustered) / len(original)) * 100\n",
    "\n",
    "\n",
    "def save_cluster_labels_csv(model, algo, image_names, original_labels, labels):\n",
    "    os.makedirs(\"clustering_labels\", exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"image_name\": image_names,\n",
    "        \"original_label\": original_labels,   # ← human-readable\n",
    "        \"cluster_label\": labels               # ← cluster assignment\n",
    "    })\n",
    "\n",
    "    filename = f\"clustering_labels/{model}_{algo}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7bb797-a02e-480f-98bf-5c57c32c55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_algorithms(X):\n",
    "    \"\"\"\n",
    "    Returns clustering algorithms that do NOT require training images.\n",
    "    \"\"\"\n",
    "\n",
    "    X_norm = normalize(X)\n",
    "\n",
    "    return {\n",
    "\n",
    "        # ================= PARTITION-BASED =================\n",
    "        \"KMeans\": KMeans(n_clusters=NUM_CLASSES, random_state=42),\n",
    "\n",
    "        \"MiniBatchKMeans\": MiniBatchKMeans(\n",
    "            n_clusters=NUM_CLASSES, random_state=42\n",
    "        ),\n",
    "\n",
    "        \"KMedoids_PAM\": KMedoids(\n",
    "            n_clusters=NUM_CLASSES, method=\"pam\", random_state=42\n",
    "        ),\n",
    "\n",
    "        \"BisectingKMeans\": BisectingKMeans(\n",
    "            n_clusters=NUM_CLASSES, random_state=42\n",
    "        ),\n",
    "\n",
    "        # Spherical K-Means (handled as callable)\n",
    "        \"SphericalKMeans\": lambda X: KMeans(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            random_state=42\n",
    "        ).fit_predict(X_norm),\n",
    "\n",
    "        # Fuzzy C-Means (callable)\n",
    "        \"FuzzyCMeans\": lambda X: np.argmax(\n",
    "            fuzz.cluster.cmeans(\n",
    "                X_norm.T,\n",
    "                c=NUM_CLASSES,\n",
    "                m=2.0,\n",
    "                error=0.005,\n",
    "                maxiter=1000\n",
    "            )[1],\n",
    "            axis=0\n",
    "        ),\n",
    "\n",
    "        # ================= HIERARCHICAL =================\n",
    "        \"Agglomerative_Single\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"single\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Complete\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"complete\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Average\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"average\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Ward\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"ward\"\n",
    "        ),\n",
    "\n",
    "        # ================= DENSITY-BASED =================\n",
    "        \"DBSCAN\": DBSCAN(eps=0.5, min_samples=5),\n",
    "\n",
    "        \"OPTICS\": OPTICS(min_samples=5),\n",
    "\n",
    "        \"HDBSCAN\": hdbscan.HDBSCAN(min_cluster_size=10),\n",
    "\n",
    "        # \"MeanShift\": MeanShift(),\n",
    "\n",
    "        # ================= MODEL-BASED =================\n",
    "        \"GMM\": GaussianMixture(\n",
    "            n_components=NUM_CLASSES,\n",
    "            reg_covar=1e-4,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        \"BayesianGMM\": BayesianGaussianMixture(\n",
    "            n_components=NUM_CLASSES,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        # ================= GRAPH-BASED =================\n",
    "        \"SpectralClustering\": SpectralClustering(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            assign_labels=\"kmeans\",\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        # ================= LARGE-SCALE =================\n",
    "        \"BIRCH\": Birch(n_clusters=NUM_CLASSES),\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069e40a7-2b35-4bb8-97b9-7108551d20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4b7d85-3922-4c18-8ee0-401664f356b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing EfficientNetB0 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 84.08%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 84.28%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 82.89%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 67.86%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 83.31%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 91.59%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 65.03%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 83.11%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 93.23%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 66.28%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 86.02%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.95%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 99.77%\n",
      "→ Implementing MeanShift ...\n",
      "   ✓ Done | Label change: 85.84%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 82.97%\n",
      "→ Implementing BayesianGMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atish\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\mixture\\_base.py:293: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 86.56%\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 81.39%\n",
      "→ Implementing BIRCH ...\n",
      "   ✓ Done | Label change: 55.44%\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 4\n",
    "MODEL_NAME = \"EfficientNetB0\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e36386-af6f-4a37-a998-7ba6d2123614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing MobileNetV3 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 76.88%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 62.34%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 77.72%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 77.52%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 73.73%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 73.06%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 86.00%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 81.95%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 85.97%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 77.03%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing OPTICS ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing MeanShift ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing GMM ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 85.91%\n",
      "→ Implementing BIRCH ...\n",
      "   ✗ Failed: Only one cluster formed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atish\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\cluster\\_birch.py:711: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (4). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 4\n",
    "MODEL_NAME = \"MobileNetV3\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e640bab-b85f-441b-acc7-6eadf00b19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Xception =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 69.38%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 75.36%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 75.47%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 71.20%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 83.00%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 68.72%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 98.98%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 87.89%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 92.25%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 77.17%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 86.00%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.92%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 87.00%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 70.98%\n",
      "→ Implementing BayesianGMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atish\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\mixture\\_base.py:293: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 70.83%\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 85.97%\n",
      "→ Implementing BIRCH ...\n",
      "   ✓ Done | Label change: 81.31%\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 4\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79850b27-21a9-4426-9f1a-7cdbe3ea2f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Change (EfficientNetB0 + KMeans) Silhouette Score: 0.8922\n",
      "Maximum Change (Xception + Birch) Silhouette Score: 0.3899\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ============================\n",
    "# LOAD FEATURES\n",
    "# ============================\n",
    "\n",
    "X_eff = np.load(\"EfficientNetB0_features.npy\")\n",
    "X_xcep = np.load(\"Xception_features.npy\")\n",
    "\n",
    "# ============================\n",
    "# LOAD CLUSTER LABEL FILES\n",
    "# ============================\n",
    "\n",
    "eff_kmeans_df = pd.read_csv(\"clustering_labels/EfficientNetB0_KMeans.csv\")\n",
    "xcep_birch_df = pd.read_csv(\"clustering_labels/Xception_BIRCH.csv\")\n",
    "\n",
    "labels_eff = eff_kmeans_df[\"cluster_label\"].values\n",
    "labels_xcep = xcep_birch_df[\"cluster_label\"].values\n",
    "\n",
    "# ============================\n",
    "# REMOVE NOISE IF PRESENT (-1)\n",
    "# ============================\n",
    "\n",
    "def compute_silhouette(X, labels, name):\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    if len(unique_labels) < 2:\n",
    "        print(f\"{name}: Cannot compute silhouette (only one cluster)\")\n",
    "        return None\n",
    "\n",
    "    # Remove noise label -1 if exists\n",
    "    mask = labels != -1\n",
    "    X_clean = X[mask]\n",
    "    labels_clean = labels[mask]\n",
    "\n",
    "    if len(np.unique(labels_clean)) < 2:\n",
    "        print(f\"{name}: Not enough valid clusters after removing noise\")\n",
    "        return None\n",
    "\n",
    "    score = silhouette_score(X_clean, labels_clean)\n",
    "    print(f\"{name} Silhouette Score: {score:.4f}\")\n",
    "    return score\n",
    "\n",
    "\n",
    "# ============================\n",
    "# COMPUTE SCORES\n",
    "# ============================\n",
    "\n",
    "score_min = compute_silhouette(\n",
    "    X_eff,\n",
    "    labels_eff,\n",
    "    \"Minimum Change (EfficientNetB0 + KMeans)\"\n",
    ")\n",
    "\n",
    "score_max = compute_silhouette(\n",
    "    X_xcep,\n",
    "    labels_xcep,\n",
    "    \"Maximum Change (Xception + Birch)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245676e2-b63f-4004-94f5-a47ccd19f4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
